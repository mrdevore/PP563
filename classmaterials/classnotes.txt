28 January 2025
    git pull = pull changes from my GitHub repository to my local one
    git pull upstream master = pull any changes from original owner's repository into my forked repository

    If there are different versions of a file between my local and GitHub repositories, I will need to
    manually open the file and change it in my text editor by deleting the parts I don't want, then pushing
    it to GitHub

    escape vims: :wq!


30 January 2025
    What is multiple sequence alignment (MSA)?
        - alignment introduces gaps to align sequences that are similar but not identical (we don't know the
        exact position in ancestors)
            - assumption: each line/column shares a common ancestor --> maybe there was a deletion or insertion
            since the common ancestor, that would leave a gap
            - we align sequences without knowing the processes that got us there, MSA helps us get there
                - purely computational, MSA aligns without knowledge of biological processes
                    - super computationally intensive!!
                - would be ideal if computer could spit out the right answer each time, but often the computer
                cannot pick the best one --> biologists must have input/opinion and make decisions at every step
        - ACAT > AGAT example:
            - would think it was a substitution
            - we have to include/decide on the cost of substitutions and the cost of indels (aka gaps) --> will direct
            computer's decisions between trees
                - cost = probability of it happening
                    - often we don't know, but we have to choose anyway
        - ACATTA > TACA based on known events (see class page)
            solution: -ACATTA
                    T--AC-A
            intutive version: -ACATTA
                            TACA---
        - alignment represents a series of events, going forward we will assume we do not have the correct alignment
            - we guide the algorithm by picking penalties for events (indels, subs)

    MSA algorithm
        - Cost of evolutionary events (going forward, check costs in software I use)
            - Ex: S=AACT S'=CTGG, indel cost=1 sub cost=3
                solution: AACT--
                        --CTGG
                        total cost = 4
            - Ex: S=AACT S'=CTGG, indel cost=4 sub cost=1
                solution: AACT
                        CTGG
                        total cost = 4
            - alignment changes even with same input based on costs assigned
                - knowledge of organism/biology can inform cost assignments, but we can never actually know
                    - CSL suggests playing with costs and seeing what you get based on your system
        - Other measures of cost
            - sequence identity
            - biochemical identity (ex. scoring likelihood of change between dif. amino acids - like in Stone Lab)
            - some gaps are more costly than others (ex. at the beginning of the sequence)

    Needleman-Wunsch algorithm
        - dynamic programming algorithm = break up large task into smaller tasks, aka recursive algorithm
            - evaluating cost of aligning two sites assumes that all sequence before those sites has been aligned already
        - requires 2 sequences and indel/sub costs
        - F = matrix representing the minimum cost to align sequences, each point in matrix reps the cost to align 
        positions with each other (ex a1 with b2 or a1 with b1)
            - F(i,j) -> i = row, j = column
                - add a gap in first position of matrix (upper left corner) then write out sequences and fill in costs
                - build out matrix from upper left corner down, for each box consider the possible answers and 
                determine the cost for each one, then pick the one with the lowest cost
                    - for each box, add the score from the box up+left from it if a substitution, from the box next to
                    it if gaps
                        - See lecture notes from CSL --> Needleman-Wunsch algorithm: Costs
                        - Because: assuming already aligned, so pull value from existing cost of alignment
                    - if two alignments have the same cost, just pick one
        - most alignment methods use Needleman-Wunsch as a base algorithm
        - when evaluating final alignment you always start at the bottom right corner, not by looking for lowest cost
                    

04 February 2025
    What we learned about Needleman-Wunsch is great for two sequences, but what about for many?
        (exapanding from pairwise to multiple sequence alignment)

    Multiple sequence alignment
        1. Progressive alignment:
            - requires a guide tree then builds the tree out from there (leaves to root)
                - guide tree is made using distances, we'll learn this in Lecture 8
                - guide tree requirement is a limitation of this method: poor guide? poor alignment
                    - fast to make, but not accurate
            - takes two sequences at a time and gradually adds more sequences (see figure in Alignment II)
            - pairwidse distances = cost calculated by Needleman-Wunsch
            - How to align alignments
                - computational algorithm, no biology at this stage
                1. convert each alignment into a profile
                    - profile = how frequently we see each nucleotide at each position, ignoring gaps
                2. combine the profiles: cost of alignment based on Needleman-Wunsch (outcome = cost matrix of substitutions)
                    - multiply the probabilities of each nucleotide in each position, pull probabilities from profile
                    - sum the products of the probability multiplying, this is the cost of aligning two positions
                    - repeat for every position and possibility (shout out to computers)
                3. Align profiles using stated cost of gaps and cost matrix for cost of substitution (make F(i,j) table)

    If you want to use a software, read the paper about it! Will give good insight for how to use and strenghts/weaknesses

    Learn@Home: Sequencing --> look for a paper with a phylogeny and follow their data availability section to access data

06 February 2025
    For sequencing homework:
        - add links to paper or databases
        - start documenting the steps for getting the data in my notebook-log.md
        - try to use 10-15 taxa/species: larger ones will take longer to run, especially later in the class
        - troubleshooting datasets: pay attention to file formats (google how to convert files if needed, office hours otherwise)
        - troubleshooting software installation: google errors, huge part of bioninformatics
            - use Slack channel!

13 February 2025
    Clarifications from last class:
    To Do: consolidate sequences into one file with new/descriptive names
        Ex. >Minc-proteinname

        - Alignment scores are only comparable within the same software
            - So... cannot compare score from T-Coffee to Muscle, but can compare scores within Muscle if parameters are different
            between alignment events
        - QualiMap: visualizing quality of alignments

---

    - phylogenetic tree is a mathmatical simplification attempting to represent the history of speciation events
        - external nodes (leaves of tree): extant species
        - internal nodes: common ancestors
        - assumptions: 
            - speciation is instantaneous, represented by strict bifurcation of tree (we know it wasn't)
            - length of tree is linearly correlated with mutation timing (not true)
            - rate of mutation is constant (also not true lol)
            - all trees are binary (each node can only split into 2)
        - from these given sequences, what is the tree that bests represents the evolution of these sequences?
            this is what a phylogenetic tree is!
    - building trees: three methods
        - distance trees: fast, but lose sequence info
        - parsimony scores
        - likelihood score (maximum or bayesian)
        Regardless of method, steps are the same:
            1. choose distance or parsimony or likelihood
            2. guess the tree
            3. evaluate the score of the tree
            4. propose a new tree
            5. evaluate the score of new tree, better than first? keep it! worse than first? back to first one, drop second
            Repeat until all trees are scored and the optimum tree is found (tree with highest score)
    
        Maximum Likelihood recipe: look at slides lol, basically calculates the likelihood of the tree input to the function
            Same for parsimony
            Good practice: use different methods to get different trees and compare to see which are best

    Phylogenetic inference:
        1. choose criterion
        2. search possible trees for optimum

    Weaknesses of above pipeline:
        - We don't know what the function looks like, so we need to evaluate a ton of trees. There's no way to
        evaluate all of them, and as the number of samples increases the number of possible trees is so frickin high
            ex. 52 samples, # of trees > # atoms in universe
            So... use different strategies to try and find optimum, like starting from different trees
            with large numbers of samples, make sure to check how the algorithm decided to stop!
        - Depends on substitution model which is chosen by the user 
        - Depends on quality of data: number, alignment quality, etc.

    Example Maximum Likelihood Software: RAxML (Stamatakis 2006)
        - CSL critique: developers are only focused on speed, not on accuracy. Testing with so many samples in tree that 
        there is no guarantee of a correct tree; did not test enough trees
            - Make sure to pay attention to the tree they start with: the bigger the space, the better the starting tree needs to be

    How to navigate the tree space:
        - 3 ways to adjust trees (LOOK AT CSL'S SLIDES FOR FIGURES), check algorithms for what kind of steps they take
            1. NNI (nearest neighbor interchange): simplest; focus on one edge of the tree that connects two clades, remove the edge and randomly 
            reconnect the clades then evaluate the new tree
                - keeps most of the tree fixed: what happens in each clade is the same, it's just how the clades are
                related to each other
                    - why NNI is often called the "smallest" step you can take in the tree space
            2. SPR (subtree pruning and reconnecting): cut edge and reconnect (I don't understand how this is different from NNI)
            3. TBR: cut edge and add a new edge in between two random edges
            - want a method that tests all three steps
                - only NNI would be really really slow
                - some algorithms ask the user to determine the frequency of each step
            
    Homework: focus on generating alignment for my sequence data!

18 February 2025
    - Distance-based trees are faster because you don't have to explore all of the tree space
        - algorithm relies on how accurate the distances are

    - Choices: 1. what kind of distance 2. what algorithm to build tree
        - types of distance
            - p-distance: proportion of nt sites that differ between two sequences (#dif/total#)
                - visualized/outputted as a matrix with same # of rows/cols as # of sequences and the distances in each entry
                - simplest distance method
                - tends to be biased: mutations don't accumulate at the same rate in dif orgs/seqs
                    - so.. not often used, use a more complex model "of evolutionary distances"
            - evolutionary distances: accounts for mutation rates, most commonly used to calculate distances

    Today: assuming we already have distances, how do we make a tree? (Cluster analysis)
        Simplest algorithm: UPGMA/WPGMA
            Start with a pairwise distance matrix then...
                1. put together taxa with smallest distance
                2. add the next closest by calculating distance from first two to all others
                    d(AB)k = (d(a,k)+d(b,k))/2
                    when doing this, keep track of what you are joining when you make the new matrix
                3. repeat until all taxa are included
                - complication: if there are two idential score, one has to be selected arbitrarily
            As you increase the length of your sequence, you converge on the wrong tree (because it doesn't account of mutation rates)
                So.. most people do not use distance-basd trees, but still good to know and understand
            Also.. lose sequence information, so people don't like that bc going based on distance matrix
            Ultrametric tree: same distance from root to all tips (implicitly assumes same rate of evolution for each extant taxa)

        Neighbor-joining tree:
            Also starts with a pairwise distance matrix
                1. sum all distances for each node (taxa) aka net divergence (r)
                    - accounts for if one node is super far from all the others because it evolves very quickly relative to the rest of the taxa
                2. create rate-corrected distance matrix
                3. look at website, but basically do the UPGMA steps with the corrected rates/distances (with inclusion of branch lengths)
                Be careful! original distances are d, updated distances are r

        Distance-based methods can be run in/through R

20 February 2025 - Guest Lecture
    What is parsimony?
        - Ockham's razor: the simplest explanation is the most likely one
        - what are the fewest changes needed to get to a tree that explains our data?
        - parsimony does not rely on a model of evolution (different from distance methods)
            - useful when more complex methods won't work or if you don't want to make the assumptions associated with other methods
            - good option when rate of evolution/mutation is slow
                    ex. super conserved things
                - not a good option for things that evolve quickly or faster than others (ie noncoding regions)
            - shown to be statistically inconsistent as you increase the number of samples

    Process of Parsimony:
        1. determine the amount of character change to explain the data with a given tree (tree topology)
        2. try all possible tree topologies, scoring each to find the best

        Includes costs for subs and indels (unweighted if costs are the same, weighted if not)

        Fitch algorithm: does the parsimony scores for us, uses equal costs
            - goes through all the internal nodes and computes the changes needed at each node to get this tree
            - parsimony at the tip is zero because no changes need to be made

    Homework: redoing the tree and calculating the scores

    Method for unequal costs: Sankoff algorithm
        Ex. mutation b/w purine and pyrimidine
        Ex. changes between amino acids based on characteristics (polarity, charge, size, etc)
        Still a little arbitrary, but tries to account for differences in costs

    Newick/Paranthetical Format of a tree: ((W,Y),(X,Z));
        Anything in a set of parentheses is a clade, commas are nodes
             /\
            /  \
           /    \
          /\    /\
         /  \  /  \
        W    Y X   Z

        Represent branch length as: ((W:2,Y:3):4,...)
            Branch leading to W has a length of 2, to Y has length of 3, to clade has length of 4
        Semicolon: represents that the tree is rooted, unrooted if ; is absent

    R Crash Course:
        ?functionname: gives info on function in lower right window
        write.tree(treename) = newick format for tree
        write.tree(treename,filename) = makes a file with that tree

25 February 2025 - Guest Lecture, R tutorial
    - today: following along with distance/parsimony-based tutorials

    in R: >?function (like >?dist.dna): tells you all the arguments needed for that function and describes the options for those arguments

    more notes in distance and parsimony R file!

27 February 2025: Models of Evolution
    - distance and parsimony methods are outdated, but they still teach them because it's where the field started
        - now most people use likelihood and bayesian methods

    Starting the slides now:
    - What is a model? A simplification of real life so we can ask and answer questions
        - Example: predicting the number of bikes that will pass your bus stop each day
            use the Poisson model to calculate and use the average number of bikes per day for lambda
                - lambda value (average number of bikes) determines the mean value and shape of the distribution
                - only one parameter (lambda), so not capturing all variability --> this is the point of models, they simplify things for us
                (look at slides for equation) 
                (fun fact from melette: poisson = fish in french)
        - models will never be perfect, have to balance accuracy of model with usefulness of model
            - more accurate = more complicated and more difficult to use
            - Example: Boston subway map is super simplified and definitely not accurate (stops are not equidistant and subway does not travel
                in a straight line), but it's more useful for taking the subway than the super realistic satellite image map
        - How do we know if a model is useful?
            1. are the assumptions accurate?
            2. what is the quality of the input data?
                - if you use a model and get weird results: it might not be the model, it's probably your data!
    
    - In phylogenetics we want the probability that we will see particular mutations in our sequences
        What is the probability that I observe these sequences if I have this tree? (looking at simple tree with DNA slide)
        - Assumptions: not true, but have to do this for our models to be useful; models exist that get around these but we won't worry about them
            (the slides have transitions that help make these clearer)
            1. the mutation process is the same at every branch of the tree, each branch will use the same probability model/equation
                (this assumption exists for all phylogenetic tools we will use)
                - Implication: focus on mutations between two sequences
            2. all sites evolves independently
                - would be computationally intense to do otherwise
                - Implication: we can focus on mutations between two sites
            3. all sites evolve the same (mutation process is the same regardless of what kind of sequence)
                - Implication: we can use any site to model the mutation process
        - How likely is it that we went from A to A in time t?
            - even though we start and end with the same nucleotide, there still could have been mutations throughout t
            - Poisson equation: in slides; mu=mutation rate t=branch length/time
                - mutation rate = number of mutation events
                    - mutation =/= substitution, A>A is still a mutation but not a substitution, A>G is both a substitution and a mutation
                    - so mutation rate/events includes A>C, A>T, A>G AND A>A
                - why a Poisson distribution? no reason, arbitrary decision but now everyone uses it
                - need to know what the probability of each mutation event is, so we need a probability matrix
                    - estimate these numbers from data
                    R probability = probability of going from nt>nt in one step
                    P probability = probability of going from nt>nt in whole branch length/time t

                    i zoned out for a few min

                - choosing a substitution model means choosing Q, which is the likelihood of various base changes, similar to choosing costs
                - Markov chain: jumping between possibilities, you keep track of where it goes
                    - probability of the next step only depends on the current one, ignoring all the steps before the current one (frog jumps)
                - did not go over ergodic or time-reversible assumptions
            - First model ever: Jukes-Cantor (1969) - assumes everything is equally likely and all sites are equally present in data (25% A, 25% G, etc)
                - has explicit formulas for transitions, one of the only ones (most models don't have explicit formulas)

            - Slide with assumptions and papers under them: papers are models that try to fix that assumption
                - new norm for assumption 3: allowing each site to have its own mutation rate

04 March 2025
    - when we choose a substitution model we are choosing Q, numbers are estimated from data
        - for protein, be less flexible
    - felsenstein model: doesn't matter what nt the site is becoming, just where it's starting
    - most people use GTR, most complex so people assume it's the best
        - not necessarily true: pick model based on whether it fits for your data
        - need to do model selection tests when making probability-based trees
    - landscape of the mountains is determined by the model, tree optimum (mountain) will change with model and where you start
    - since we don't know the sequence at the internal nodes, the algorithm will search for the sequences that is most likely given the sequences at the tips of the tree
    - every single probability method has the same three assumptions (the ones from the last lecture)
        - also assumes that the way things are evolving is the same from the root to the tips of the tree, this probably isn't true though (but pretend it is)
        - first two assumptions are not biologically realistic, but the models still work and give us very accurate trees

06 March 2025: Maximum Likelihood Theory
     Steps:
        1. Choose a substitution model (choosing Q)
        2. For a given tree, what is the likelihood?
        3. Search tree space for one that maximizes the likelihood
    
    NNI: nearest-neighbor interchange --> rearranges 4 clades

    Can't pick your starting tree, but can pick how many you want to start with: helps avoid getting stuck in local maxima that aren't actually the best tree
        - there are usually default values, make sure to look at them and change!
            - usually work well for small sample sizes, but the larger your sample the more starting trees you should have

    UPGMA and maximum parsimony are bad statistically, bayesian and maximum likelihood are statistically good/consistent and converge to the true tree
        - but more computationally expensive, so they take longer to run

18 March 2025: Bayesian Inference
    - Maximum likelihood trees: RaxML + IQTree
        - make sure to root with outgroup
        - make sure to plot in R
    
    - In Bayesian inference, you want to combine two kinds of information:
        - Prior: subjective information based on your knowledge
            - people sometimes have an issue with this but priors aren't super weighted
            - want to avoid restricting too much via the prior, should have variability in the distribution
        - Likelihood: from the data (this is all Maximum Likelihood methods care about)
        - Prior * Likelihood = Posterior distribution
            - mixes two fxns into one
            - Example in class: prior is pulling the likelihood distribution and it's optimum toward where the prior is (actual mean = 8.4, adding prior changes to 6.smth)
            - Priors are good to use when the likelihood is very flat/not well defined
                - prior allows you to find optimums when you can't get them from the data
                - there is still a point estimate (like in max like) but the spread helps with confidence in our point value
                    - if the distribution is very skinny then we are more certain, if wide then there is a lot of variability
            - sample size is important: small --> posterior is more like the prior, large --> posterior is more like ML distribution
        - Considerations:
            - Likelihood: substitution model, model assumptions, does the data have enough signal?
            - Prior: which prior model, model assumptions, how does this affect inference?
                - non-informative prior: same peak/distribution as ML
                    but still use so you can see the shape of the distribution rather than using just ML and getting a single point output
        - conjugate prior: when the prior and the posterior have the same distribution (ex. gamma) - RARE
        - Bayesian =/= MCMC
            - If we have an explicit formula for the posterior, we don't need MCMC - RARE
            - MCMC = Markov chain Monte Carlo
                - a way to approximate the posterior when we don't have an explicit form - MOST OF THE TIME
                * All Bayesian phylogenetic methods do MCMC, it is slow but it works
                    - people are trying to get away from it, but posterior approximation is difficult and MCMC works really well
                    - MCMC traverses the whole space to see what the landscape looks like so we can get the posterior distribution
                        (posterior dist is the landscape)
                - Have to pick a "Proposal Distribution" for the model to test around at the start: usually symmetric, determined by the Hasting ratio

    - MCMC considerations:
        - Mixing: how well was the tree space navigated? 
            - thoroughness of exploring tree space
            - governed by the Proposal Distribution
                Rule of Thumb: want acceptance probability of steps around tree space to be around 30%
                    - near 100% means very slow bc very small steps
                    - near 0% means very large steps
                    * can't know this ahead of time, try running on subset of data or for short time then check acceptance probability and adjust as needed
                        Theme of Class: many trials
            - Trace Plots: one way to evaluate mixing
                - y axis = value of posterior
                - x axis = steps
                Want this to look like noise, flat regions = bad mixing where it got stuck
                Programs to plot: Tracer, AWTY (Are We There Yet)
            - Cold chain vs hot chain robots: heating the chain squashes the tree space topology down so the robots avoid getting stuck in local maxima
                - need both: heated robot helps cold one jump between peaks (just a computational trick)
                - Can run MCMC without the hot chain, can run with multiple hot chains
        - Convergence: how well did you reach all regions of high posterior values?
            - didn't get stuck in one area, you want to cover all the peaks
        - Burn-in: how long to reach high posterior value regions?
            - if you start in a low region, how long to walk to high region?
        - We have to choose how long to run MCMC: if we let it run long enough it will give us the correct posterior distribution but it will not stop itself like other methods wold
            - how many steps to take?
    
    MCMC for Phylogenetics:
        1. Start with a random tree and arbitrary branch lengths and model parameters
        2. New generation: one of the following
            A. Propose new tree and reject or accept after comparison
            B. Propose new parameters and evaluate
        3. idk more stuff she went fast
        4
        5
        6
        - End with trees that were visited and look for trees that were visited the most (these have high posteriors)
            - MCMC keeps track of every change and parameter/tree tested


03 April 2025
- Run IQtree on data: it will tell me what model to use
- Pick priors based on paper i got my data from

- MrBayes will not work on my computer :O I will have to use RevBayes
    - for MrBayes homework: make the block of code in a nexus file and submit, don't need to actually run
    - CSL suggested downloading BEAST instead!
        - downloaded through conda, here's how to activate it:

08 April 2025 - The Coalescent Model
* No need to do this for project, still have homework for it

    - different parts of the genome can generate different trees, previously concantenation would just combine all the trees
        - this was the norm in the 90s, early 2000s showed that his approach is statistically inconsistent, especially as the number
        of trees being combined increases
        - now: make a gene tree using an alignment method (MrBayes, IQtree, etc) then combine the trees using an orthologous region
        between each taxa
            - find recombination-free areas using MDL program (Ane' 2011)
        - coalescent model takes gene trees and makes species trees

    What is the coalescent model?
        - branches are usually thick, indicating that this tree encompasses populations. circles on the branches indicate individuals
        - tracks generations over time from present to past, a coalescent event is when two current individuals have a common ancestor
            - want to know how long until reaching common ancestor, this will depend on who is sampled
            - different parts of the genome will coalesce at different times in ancestral populations: different gene trees
                - from the array of gene trees you get from the genome, which is most likely?
                    "How good of a fit is this species tree for these gene trees?" (previous questions)
                    "What is the probability that I observe this gene tree from this candidate species tree?" (what we want)
        - branches =/= time, = coalescent units (time divided by population size)
        - species tree with short internal branches may result in tons of different gene trees, this can happen with rapid speciation because
        there was not enough time for the populations to coalesce
        - most widely used method: ASTRAL
            - BUCKy made at UWM
            - BEAST also common

        - When we build trees, we assume the alignment is perfect. When we build species trees, we assume the gene trees are perfect.
            - so why separate steps? so it can be scalable to larger datasets
                - 10 taxa max on doing it all together with co-estimation, more than 10 you need to use a coalescent model
                    - small enough dataset: always run BEAST! most robust method
            - very few user choices in building species tree from gene trees because building from gene trees where we made a bunch of choices 
                * with summary methods
                * if using Bayesian or MaxLik methods, need to set priors and all that stuff

        - anomaly zone: why concantenation does not work!
            - if your species tree has really long branches, then the gene tree that is the most likely is the one that matches the species tree
            - if your species tree has really short branches, then most of your gene trees will be different from the species tree, even if the 
                species tree is known to be the "true" tree
                    * this is where the anomaly zone is, and this is why concatenation is bad/inconsistent

15 April 2025 - Coalescent Network Theory (SNaQ)

    General Updates
        - will not do computer work for this, but there is a tutorial in the class GitHub
        - converting files: CSL made her own julia script (julia is another programming language) that does this for us
            - we can use if we download julia, she shared in the slack
            - there may be scripts online for R or Python built into packages

        In my repository/reproducible script: 
            - links and information to softwares
            - if following a tutorial, link it
            - want a chain of custody for files: 
                1. what was the input
                2. what was the process/software
                3. what was the output
                4. where to find the files/folders
            - repository should contain names of files and paths in the commands

    Class content:
        - what is a phylogenetic network? a mathematical simplification of biology
            - signal in data that is not exactly tree-like, there is overlap between populations that cannot be explained by a tree
                - can be represented by an arrow between tree branches: there was some gene flow event
                -  can result from introgression
            - can be explicit or implicit:
                - explicit: we know if the node is speciation or hybridization; we know the process/event that led to the hybridization
                    - has a number that tells what proportion of genes were transferred through that process (hybridization or normal)
                - implicit: we don't know what kind of node (lose biological info), no time, unrooted; faster for reconstruction, were preferred for a while
                * always want to make explicit networks, takes more time but is much more useful
                    - implicit networks only tell you that there is discordance
        - why build a phylogenetic network?
            - if you ignore gene flow that is there you can estimate the wrong tree: so, making a main tree without the hybridization is not always good
                (main tree = tree without arrows)
            - coalescent methods are not good for estimating trees when there have been gene flow events
                - get the wrong tree more with larger gene flow events and more genes to estimate the tree from (given sequence of extants)
            - you can always get the main tree from the network
        
        - Most people who are building networks first estimate gene trees then estimate networks, you can do both at the same time with BEAST2 or PhyloNet,
            but this is super computationally expensive
            - biggest dataset that can be used: 50 taxa

        SNaQ: Pseudolikelihood method
            - evaluating the likelihood of networks is super computationally expensive, SNaQ evaluates likelihood on subnetwork quartets which is much faster
                - can do all subsets of 10 in less time than evaluating one new network of 10
                - phylonet could do max 10 taxa with 100 genes (it does traditional likelihood)

            - challenges of building networks
                - identifiability:
                    - if the tree space is flat all trees have the same likelihood: means there is not enough signal to understand which tree is best
                    - we have no idea how many networks are identifiable still
                        - only types of networks that are identifiable: Level 1 Networks (no gene flow cycles are touching, closer to a tree)
                            (gene flow cycles are the circles created by the arrows representing gene flow events)
                            - cannot detect gene flow between sister taxa, but can if gene flow is between distant relatives (unfortunate biologically)
                            - also, only some of the cycles are identifiable with a reasonable number of genes
                - network space is huge

            - you don't always need a network, TICR helps determine if a tree is a good fit for the data
                - tests whether variability in gene trees is well explained with a species tree: yes? then use tree methods! no? then network methods!
                    - statistical test! there could still be gene flow, but no signal from it to be detected (might need more data!)
                - TICR is available as an R or julia package (https://github.com/nstenz/TICR)

            - PhyloNetworks package: has SNaQ, Julia, etc
            - don't have to run these methods for your project!

17 April 2025 - Co-estimation Methods
    - Beast is very very widely used, but may not scale well to large datasets

    - Co-estimations don't need gene tree inputs, they actually use the sequence and estimate the gene trees as they work on the species trees; accounts
    for error in gene trees as it does things; very slow, so doesn't scale well
        - other methods that start with gene trees assume that the gene trees are perfect

    - For Beast tutorials and resources: Taming the Beast 
        includes troubleshooting, prior selection, etc. --> super useful!!
    - Beast gives branch lengths in time and estimates population sizes

    Beast Slides:
        - Inputs: genetic sequences, geneology, demographic model, site model, molecular clock model
            - Genetic sequences: assumes data are correct; want to include collection times bc beast can do calendar time branch lengths
            - Geneology:
                - homochronous tree: all tips at the same timepoint
                - heterochronous tree: tips from different timepoints
            - Demographic Models: calculate the probabilities of trees, how you choose which trees to weigh heavier
                - coalescent model: goes from tips to roots, sees when two populations coalesce with a common ancestor
                - birth-death model: goes from root to tips, events take dif amounts of time
                    - birth = speciation, death = extinction
            - Site Models: substitution model, how to weigh substitutions and indels 
                 - Beast can help you choose the right model and will allow you to use different models for different genes in the same run
            - Molecular clock model: rate per branch, not sites
                - molecular clock: we assume the mutation rate is constant; genetic distance = rate x time
                - relaxed clock: different mutation rates in different branches

        - look into software Beauti: helper for Beast with a GUI, helps pick priors, MCMC operators, etc; creates file that beast needs for input
        - other software to help:
            - Tracer: will help look at convergence and effective sample sizes: use to check!
                - if you think it has converged, add another million and see if it stays converged or peters off
                - input log file
                - pay attention to ESS column (effective sample size): red is too small, yellow isn't great, black is good
                    sample size is when you pull trees from the MCMC chain to evaluate
                    - you don't want any red! to fix that, just run it longer and see if it goes away; if you do that and the numbers don't change, 
                        you need to change your proposals
            - TreeAnnotator: put your tree file into it
            - GGTree for R after TreeAnnotator

        - Beauti2:
            - input: sequence data required; optional sampling times, locations, etc
            - output: xml file to use with Beast
            - prior selection: will give you a graph of the prior so you can select, want to avoid very tight/narrow/biased priors

        Beast Best Practice:
            1. Run without data, sanity check with priors and that way if nothing changes with your data then you know your data isn't good
            2. Run analysis with multiple chains
            3. Combine chains
            4. Assess convergence and mixing

22 April 2025 - BEAST
    - in Beauti, start with an upgma tree (it's a better starting point)
    - operators = proposal distribution
    - length of chain should always be in the millions
        1. set number 2. run 3. check convergence
            if converged: yay, if not: run with a longer chain

24 April 2025 - What Else is Out There?
    - Claudia likes T-Coffee! Highlight this in my final project
    - Check how many gaps there are in the alignment, if RaxML says that 95% of my alignment is gaps, then that alignment isn't useful
    - low bootstrap support may not be bad, could point at an area where something interesting is happening
    - there is no perfect pipeline, the best we can do is say "these are the choices we made, here's the analysis"
    